{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb50695-99eb-4eff-a8e8-e9d7aa96b93a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dask_awkward as dak\n",
    "import awkward as ak\n",
    "from distributed import LocalCluster, Client, progress\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import mplhep as hep\n",
    "import glob\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "client =  Client(n_workers=15,  threads_per_worker=1, processes=True, memory_limit='8 GiB') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a7449a-0e85-4ea1-804f-ea77ea2c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHist(events, field2plot, binning):\n",
    "    weight = ak.fill_none(events.wgt_nominal_total, value=0)\n",
    "    value = ak.fill_none(events[field2plot], value=-999)\n",
    "    # use np.isnan to filter away remaining nan values\n",
    "    nan_filter = ~(np.isnan(weight) | np.isnan(value)) # some nans are not None, apparently\n",
    "    weight = weight[nan_filter]\n",
    "    value = value[nan_filter]\n",
    "    \n",
    "    print(f\"getHist weight sum: {np.sum(weight)}\")\n",
    "    print(f\"getHist value sum: {np.sum(value)}\")\n",
    "    print(f\"getHist weight: {weight}\")\n",
    "    print(f\"getHist value: {value}\")\n",
    "    # print(f\"getHist is none weight: {ak.sum(ak.is_none(weight))}\")\n",
    "    # print(f\"getHist is none value: {ak.sum(ak.is_none(value))}\")\n",
    "    # weight = weight/ np.sum(weight) # normalize to one\n",
    "    # print(f\"np.sum(weight): {np.sum(weight)}\")\n",
    "    hist, edges = np.histogram(value, bins=binning, weights=weight)\n",
    "    print(f\"getHist hist b4 normalization: {hist}\")\n",
    "    hist = hist / np.sum(hist)\n",
    "    print(f\"np.sum(hist): {np.sum(hist)}\")\n",
    "    return hist, edges\n",
    "\n",
    "def applyGGH_cut(events):\n",
    "    btag_cut =ak.fill_none((events.nBtagLoose >= 2), value=False) | ak.fill_none((events.nBtagMedium >= 1), value=False)\n",
    "    # vbf_cut = ak.fill_none(events.vbf_cut, value=False\n",
    "    vbf_cut = (events.jj_mass > 400) & (events.jj_dEta > 2.5) \n",
    "    vbf_cut = ak.fill_none(vbf_cut, value=False)\n",
    "    region = events.h_sidebands | events.h_peak\n",
    "    # region =  events.h_peak # whether just h_peak or signal region, the plots don't change\n",
    "    ggH_filter = (\n",
    "        ~vbf_cut & \n",
    "        region &\n",
    "        ~btag_cut # btag cut is for VH and ttH categories\n",
    "    )\n",
    "    return events[ggH_filter]\n",
    "\n",
    "def getDeltaPhi(phi1,phi2):\n",
    "    dphi = abs(np.mod(phi1 - phi2 + np.pi, 2 * np.pi) - np.pi)\n",
    "    return dphi\n",
    "\n",
    "def computeBkgFromParquet(load_path, bkgSample_l, fields2compute):\n",
    "    zip_l = []\n",
    "    # fields2compute =  fields2compute +[\"wgt_nominal_zpt_wgt\"]\n",
    "    for sample in bkgSample_l:\n",
    "        events = dak.from_parquet(load_path+f\"/{sample}/*/*.parquet\")\n",
    "        # print(events.fields)\n",
    "        # print(events.wgt_nominal_zpt_wgt)\n",
    "        events[\"jj_dRapidity\"] = np.abs(events.jet1_rapidity - events.jet2_rapidity)\n",
    "        events[\"mmj1_dRapidity\"] = np.abs(events.jet1_rapidity - events.dimuon_rapidity)\n",
    "        events[\"mmj2_dRapidity\"] = np.abs(events.jet2_rapidity - events.dimuon_rapidity)\n",
    "        events[\"jj_dPhiV2\"] = ak.fill_none(getDeltaPhi(events.jet1_phi, events.jet2_phi), value=-1)\n",
    "        bool_filter = ak.fill_none((events.mmj1_dEta < events.mmj2_dEta), value=True)\n",
    "        events[\"mmj_min_dEtaV2\"] = ak.where(bool_filter, events.mmj1_dEta, events.mmj2_dEta)\n",
    "        bool_filter = ak.fill_none((events.mmj1_dPhi < events.mmj2_dPhi), value=True)\n",
    "        events[\"mmj_min_dPhiV2\"] = ak.where(bool_filter, events.mmj1_dPhi, events.mmj2_dPhi)\n",
    "        zip = ak.zip({field: events[field] for field in fields2compute}).compute()\n",
    "        zip_l.append(zip)\n",
    "    \n",
    "    final_zip = ak.concatenate(zip_l)\n",
    "    # zpt removal test start ------------------------\n",
    "    # final_zip[\"wgt_nominal_total\"] = final_zip.wgt_nominal_total / final_zip.wgt_nominal_zpt_wgt\n",
    "    # zpt removal test end ------------------------\n",
    "    return final_zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67323fa4-14bd-4c8e-9cae-a35ccae64249",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = {\n",
    "        \"background\": [ # for some reason, having more than dy causes things to break\n",
    "            \"dy_M-100To200\", \n",
    "            \"ttjets_dl\",\n",
    "            \"ttjets_sl\",\n",
    "            \"st_tw_top\",\n",
    "            \"st_tw_antitop\",\n",
    "            \"ww_2l2nu\",\n",
    "            \"wz_1l1nu2q\",\n",
    "            \"wz_2l2q\",\n",
    "            \"wz_3lnu\",\n",
    "            \"zz\",\n",
    "            \"ewk_lljj_mll50_mjj120\",\n",
    "        ],\n",
    "        \"signal\": [\n",
    "            \"ggh_powheg\", \n",
    "            \"vbf_powheg\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e2e9db-ff9b-40c9-854f-d863988559a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = 2018\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/DNN_test2/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_V2/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_V2/*/f1_0\"\n",
    "load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_JetIdUpdate/*/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_JetIdUpdate/2018/f1_0\"\n",
    "# bkg_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"background\"]]\n",
    "# bkg_l = []\n",
    "# for bkg in training_samples[\"background\"]:\n",
    "#     bkg_l += glob.glob(load_path+f\"/{bkg}/*/*.parquet\")\n",
    "# simple from parquet doesn't work on bkg, so special care is needed\n",
    "\n",
    "# bkg_l\n",
    "# sig_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"signal\"]]\n",
    "# sig_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9b8a5b-db56-477d-8495-d5c71af8834d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.74763464927673\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cols_of_interest = [\n",
    "    'dimuon_rapidity',\n",
    "    'dimuon_cos_theta_cs',\n",
    "    'dimuon_phi_cs',\n",
    "    'dimuon_pt',\n",
    "    'jet1_eta',\n",
    "    'jet1_pt',\n",
    "    'jet2_pt',\n",
    "    'jet2_eta', # for test purpose\n",
    "    'jj_dEta',\n",
    "    'jj_dPhi',\n",
    "    'jj_dPhiV2',\n",
    "    'jj_mass',\n",
    "    'mmj1_dEta',\n",
    "    'mmj1_dPhi',\n",
    "    'mmj_min_dEta',\n",
    "    'mmj_min_dPhi',\n",
    "    'mmj_min_dEtaV2',\n",
    "    'mmj_min_dPhiV2',\n",
    "    'mu1_eta',\n",
    "    'mu1_pt_over_mass',\n",
    "    'mu2_eta',\n",
    "    'mu2_pt_over_mass',\n",
    "    'zeppenfeld',\n",
    "    'njets',\n",
    "    # \"jj_dRapidity\", # for test purpose\n",
    "    # 'mmj1_dRapidity', # for test purpose\n",
    "    # 'mmj2_dRapidity', # for test purpose\n",
    "    # 'mmj2_dEta',# for test purpose\n",
    "    # 'mmj2_dPhi',# for test purpose\n",
    "]\n",
    "additional_fields = [\n",
    "    \"wgt_nominal_total\",\n",
    "    \"h_sidebands\",\n",
    "    \"h_peak\",\n",
    "    \"vbf_cut\",\n",
    "    \"nBtagLoose\",\n",
    "    \"nBtagMedium\",\n",
    "    # \"mu1_pt\",\n",
    "    # \"mu2_pt\",\n",
    "    \"dimuon_mass\",\n",
    "    \"jet1_rapidity\",\n",
    "    \"jet2_rapidity\",\n",
    "    \"jet1_phi\",\n",
    "    \"jet2_phi\",\n",
    "]\n",
    "fields2compute = cols_of_interest +  additional_fields\n",
    "\n",
    "\n",
    "# events_bkg = dak.from_parquet(bkg_l) \n",
    "# events_bkg = ak.zip({field : events_bkg[field] for field in fields2compute}).compute()\n",
    "\n",
    "# normal from_parquet doesn't work, so using convoluted concatenating method\n",
    "\n",
    "events_bkg = computeBkgFromParquet(\n",
    "    load_path, \n",
    "    training_samples[\"background\"], \n",
    "    fields2compute,\n",
    ")\n",
    "\n",
    "\n",
    "events_bkg = applyGGH_cut(events_bkg)\n",
    "\n",
    "#calculate sig_l\n",
    "sig_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"signal\"]]\n",
    "events_sig = dak.from_parquet(sig_l)\n",
    "events_sig[\"jj_dRapidity\"] = np.abs(events_sig.jet1_rapidity - events_sig.jet2_rapidity)\n",
    "events_sig[\"mmj1_dRapidity\"] = np.abs(events_sig.jet1_rapidity - events_sig.dimuon_rapidity)\n",
    "events_sig[\"mmj2_dRapidity\"] = np.abs(events_sig.jet2_rapidity - events_sig.dimuon_rapidity)\n",
    "events_sig[\"jj_dPhiV2\"] = ak.fill_none(getDeltaPhi(events_sig.jet1_phi, events_sig.jet2_phi), value=-1)\n",
    "bool_filter = ak.fill_none((events_sig.mmj1_dEta < events_sig.mmj2_dEta), value=True)\n",
    "events_sig[\"mmj_min_dEtaV2\"] = ak.where(bool_filter, events_sig.mmj1_dEta, events_sig.mmj2_dEta)\n",
    "bool_filter = ak.fill_none((events_sig.mmj1_dPhi < events_sig.mmj2_dPhi), value=True)\n",
    "events_sig[\"mmj_min_dPhiV2\"] = ak.where(bool_filter, events_sig.mmj1_dPhi, events_sig.mmj2_dPhi)\n",
    "\n",
    "\n",
    "\n",
    "# events_sig[\"wgt_nominal_total\"].compute()\n",
    "events_sig = ak.zip({field : events_sig[field] for field in fields2compute}).compute()\n",
    "events_sig = applyGGH_cut(events_sig)\n",
    "\n",
    "print(time.time()-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bea02ca-2935-4d97-b8d6-67bb6bc2e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnan = np.isnan(ak.to_numpy(events_bkg.wgt_nominal_total))\n",
    "# np.sum(isnan)\n",
    "# # hist_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aef3c9f-d2f2-4a80-b2ab-b27a9bd642ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nbins = 60\n",
    "# bin_map = {\n",
    "#      \"dimuon_pt\": [0,200, nbins], \n",
    "#     \"dimuon_rapidity\" : [-2.5,2.5, nbins], \n",
    "#     \"dimuon_eta\" : [-8,8, nbins],\n",
    "# }\n",
    "with open(\"./plot_settings.json\", \"r\") as file:\n",
    "    bin_map = json.load(file)\n",
    "# bin_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa3ae764-41bf-4936-8cca-5ff778ddd9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getHist weight sum: 881.5309439082096\n",
      "getHist value sum: -971341.2022340298\n",
      "getHist weight: [0.000379, 0.000224, 0.000261, 0.000312, ..., 2.23e-05, 2.45e-05, 3.51e-05]\n",
      "getHist value: [-1, -1, -1, -1, -1, -1, -1, -1, ..., -1, 2.95, -1, -1, 0.453, -1, -1, 0.521]\n",
      "getHist hist b4 normalization: [2.52, 2.54, 2.68, 2.65, 2.78, 2.8, ..., 3.19, 3.17, 3.3, 3.34, 3.51, 3.54]\n",
      "np.sum(hist): 1.0\n",
      "getHist weight sum: 1737178.0372940407\n",
      "getHist value sum: -20602466.336598516\n",
      "getHist weight: [0.0293, 0.0325, 0.0273, 0.0258, -0.0255, ..., 0.0103, 0.0119, 0.0113, 0.0143]\n",
      "getHist value: [-1, -1, -1, -1, -1, -1, -1, -1, -1, ..., 2.33, -1, -1, -1, 1.49, 1.8, -1, 2.28]\n",
      "getHist hist b4 normalization: [2.52e+03, 2.6e+03, 2.57e+03, 2.66e+03, ..., 7.31e+03, 7.59e+03, 7.93e+03]\n",
      "np.sum(hist): 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year = \"Run2\"\n",
    "# for field in cols_of_interest:\n",
    "for field in ([\"jj_dPhiV2\"]):\n",
    "    binning = np.linspace(*bin_map[field][\"binning_linspace\"])\n",
    "    xmin = bin_map[field][\"binning_linspace\"][0]\n",
    "    xmax = bin_map[field][\"binning_linspace\"][1]\n",
    "    hist_sig, edges = getHist(events_sig, field, binning)\n",
    "    # raise ValueError\n",
    "    hist_bkg, edges = getHist(events_bkg, field, binning)\n",
    "    fig, ax_main = plt.subplots()\n",
    "    # plt.stairs(hist_sig,edges=edges,label=\"signal\", color=\"blue\")\n",
    "    # plt.stairs(hist_bkg,edges=edges,label=\"background\", color=\"red\")\n",
    "    hep.histplot(\n",
    "        hist_sig, \n",
    "        bins=binning, \n",
    "        stack=False, \n",
    "        histtype='step', \n",
    "        color='blue', \n",
    "        label='signal', \n",
    "        ax=ax_main,\n",
    "    )\n",
    "    # print(f\"hist_bkg: {hist_bkg}\")\n",
    "    hep.histplot(\n",
    "        hist_bkg, \n",
    "        bins=binning, \n",
    "        stack=False, \n",
    "        histtype='step', \n",
    "        color='red', \n",
    "        label='background', \n",
    "        ax=ax_main,\n",
    "    )\n",
    "    ax_main.set_xlabel(bin_map[field][\"xlabel\"])\n",
    "    ax_main.set_ylabel(\"A.U.\")\n",
    "    if bin_map[field][\"logscale\"]:\n",
    "        plt.yscale('log')  # Set y-axis to log scale\n",
    "        plt.ylim(1e-3, 1)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    CenterOfMass = 13\n",
    "    # lumi = 59.97 # 2018 lumi value\n",
    "    lumi = 137.9 # Run2 value\n",
    "    hep.cms.label(data=True, loc=0, label=\"Private Work\", com=CenterOfMass, ax=ax_main, lumi=lumi)\n",
    "    plt.savefig(f\"quick_plots/BDT_input{year}_{field}\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58dcdad5-391a-4147-9827-1b876ea26b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.sum(ak.is_none(events_bkg.jj_dPhiV2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde028c3-9f6b-4e3c-a88d-16f9c4342cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5. , -4.8, -4.6, -4.4, -4.2, -4. , -3.8, -3.6, -3.4, -3.2, -3. ,\n",
       "       -2.8, -2.6, -2.4, -2.2, -2. , -1.8, -1.6, -1.4, -1.2, -1. , -0.8,\n",
       "       -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  1.2,  1.4,\n",
       "        1.6,  1.8,  2. ,  2.2,  2.4,  2.6,  2.8,  3. ,  3.2,  3.4,  3.6,\n",
       "        3.8,  4. ,  4.2,  4.4,  4.6,  4.8,  5. ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# np.linspace(*[-0.0001, 7.9999, 9])\n",
    "np.linspace(*[-5, 5, 51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d8f7d9-d7d2-4427-820f-18d89f2aeac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events_sig = dak.from_parquet(sig_l)\n",
    "# # events_sig.fields\n",
    "# ak.all(events_sig.wgt_nominal_qgl.compute() ==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3762e25-2c72-4e48-8dfd-719c0fbd0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_wo_qgl = ak.sum(events_sig.wgt_nominal_total/events_sig.wgt_nominal_btag_wgt).compute()\n",
    "# total = ak.sum(events_sig.wgt_nominal_total.compute() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c98e3fd-dca1-4e49-a6cb-5737e42ecb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_wo_qgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ff61242-e60a-4ac0-b6ed-7a503befb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n",
    "    'Score': [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a9e040d-3eb8-4b59-aec1-4d8d60b28bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Houston</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age         City  Score\n",
       "0    Alice  NaN     New York    NaN\n",
       "1      Bob  NaN  Los Angeles    NaN\n",
       "2  Charlie  NaN      Chicago    NaN\n",
       "3    David  NaN      Houston    NaN\n",
       "4      Eve  NaN      Phoenix    NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f167994-cc03-4409-9b17-99e04606ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({\"Score\":-1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f4c168e-a472-4764-91c8-bd5a4667d4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Houston</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age         City  Score\n",
       "0    Alice  NaN     New York   -1.0\n",
       "1      Bob  NaN  Los Angeles   -1.0\n",
       "2  Charlie  NaN      Chicago   -1.0\n",
       "3    David  NaN      Houston   -1.0\n",
       "4      Eve  NaN      Phoenix   -1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40b26c1e-aef3-4614-bbd1-38c32ebb521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e7ed781-c229-402f-bd1a-53fe7fdb76de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Houston</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age         City  Score\n",
       "0    Alice  0.0     New York   -1.0\n",
       "1      Bob  0.0  Los Angeles   -1.0\n",
       "2  Charlie  0.0      Chicago   -1.0\n",
       "3    David  0.0      Houston   -1.0\n",
       "4      Eve  0.0      Phoenix   -1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951470c9-52c3-4d06-9db5-b6978c8cde2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root632]",
   "language": "python",
   "name": "conda-env-root632-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

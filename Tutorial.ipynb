{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fbbc30-121f-48f7-9b3c-e59c106491c6",
   "metadata": {},
   "source": [
    "## CopperHead V2 tutorial\n",
    "\n",
    "This framework builds upon columnar analysis platform coffea 202x python package, using awkward arrays and dask distributed for parallelization.\n",
    "\n",
    "First we setup our config by specifying the era/year we will be doing our analysis work on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d19ab0-1f67-4a82-bb57-7aeba184795b",
   "metadata": {},
   "source": [
    "# Pre-stage\n",
    "Before we \"run\" our analysis, we prepare the list of samples that we will be performing our analysis on. This can be done by executing ```run_prestage.py``` script, specifying the chunksize by using ```--chunksize``` flag and listing the samples we would like to perform our analysis on with ```--input_string``` flag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed50e0-7df3-445a-9b43-d11076c5a964",
   "metadata": {},
   "source": [
    "The chunksize value is simple: it is an integer value of \"chunks\" of rows of data that each worker works on during parallelized workflow. \n",
    "\n",
    "Moreover, one can specify the list of data runs, MC background samples and MC signal samples for the analysis to run on by using --data, --background and --signal flag respectively. If left empty/ imcompatible (ie data 'A' in year 2017), it will just skip and move on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2dd9cc-f6b7-4f3b-bdbb-12a08f0d6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = ['A', 'B', 'C', 'D']\n",
    "bkg_l = ['DY', 'TT',]\n",
    "sig_l = ['ggH', 'VBF']\n",
    "! python run_prestage.py --chunksize 100000 --year 2018 --cluster True --data {' '.join(data_l)} --background {' '.join(bkg_l)} --signal {' '.join(sig_l)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1baf3e-85d6-4561-b20a-0ab6cd6260be",
   "metadata": {},
   "source": [
    "If we wish to run our analysis only onto a subset of our samples in order to save time, for example, we can do so my specifying the fraction of the samples we would like to perform our analysis on with the ```--change_fraction``` flag with the accompanying floating value representing the fraction of the samples we want to work on.\n",
    "\n",
    "For example running this cell below would trim our  ```./config/fraction_processor_samples.json``` by approximately ten percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad2673-af7b-4797-9e3c-9e38abc46a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_prestage.py --change_fraction 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b9dcb-c1ed-4db8-b878-4b08b4186bc6",
   "metadata": {},
   "source": [
    "The code above will only less than a second. This will save a new config file ```./config/fraction_processor_samples.json```. Please note that we don't overwrite the original full config file ```./config/fraction_processor_samples.json```. This is so that if you would like to change your fraction value, you can do so quickly, instead of waiting a full minute to redo the whole prestage step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8cd851-aaf5-443c-8e60-f4b713e40838",
   "metadata": {},
   "source": [
    "# Running Stage 1\n",
    "\n",
    "Now we're ready to execute stage 1 of the analysis, which refers to the baseline selections we apply just before categorization of Higgs decay categories. we do this by simply running ```run_stage1.py```, though we recommend to also add ```-W ignore``` option to suppress warning flags. This operation takes the most time, ranging from 30 mins for fraction of around 0.25, all the way to hours for a full sample run. The outputs of the ```run_stage1.py``` will be saved as collection of ```.parquet``` files in the directory that's defined in the ```--save_path``` flag along with the sample name and fraction. \n",
    "\n",
    "For instance, data_A samples with fraction 0.25 with sample_path of ```/depot/cms/users/yun79/results/stage1/test/``` would be saved at ```/depot/cms/users/yun79/results/stage1/test/f0_25/data_A```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c248c1-d49a-4f99-aafe-905717d07400",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "save_path = \"/depot/cms/users/yun79/results/stage1/test/\"\n",
    "! python -W ignore run_stage1.py -y {year} --save_path {save_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f14fb3-aa01-4206-bb5c-b44940dea8fe",
   "metadata": {},
   "source": [
    "# Stage 1 Validation\n",
    "Now we validate our stage 1 outputs by plotting validation histograms. Like ```run_prestage.py``` script, we can specify the options of the plots via ```--input_string``` flag, but with different formating, but this time with mostly just boolean values: \n",
    "\n",
    "\n",
    "Ratio_{Y or N}/LogY_{Y or N}/ShowLumi_{Y or N}/Status_{work or prelim}\n",
    "\n",
    "Where we specify if we want Data/MC ratio plot in the bottom panel on with \"Y\" to mean yes and \"N\" to mean no after ```Ratio_```, plot in log scale in the y axis after ```LogY_```, show integrated luminosity value of the run after ```ShowLumi_``` and status of the plot after ```Status_```, where the option is \"work\" for \"Work in Progress\", \"prelim\" for \"Preliminary\" and empty character (\"\") for no mention of the status at all.\n",
    "\n",
    "Ie: Ratio_Y/LogY_Y/ShowLumi_N/Status_work indicates to have Data/MC ratio plot on the bottom, plot in logarithmic scale, don't show the integrated luminosity value, and have \"Work in progress\" label\n",
    "\n",
    "next is the ```--load_path``` flag, which should be identical to the path specified in ```--save_path``` flag when running the ```run_stage1.py``` script.\n",
    "\n",
    "One can also specify the path to where the validation plots will be saved by adding ```--save_path``` flag onto ```run_stage1_validation.py``` script, or just use the default path ```./validation/figs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8122b75-efe3-4512-a278-36ca6ad480d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_stage1_validation.py --fraction 0.001 --input_string \"Ratio_Y/LogY_Y/ShowLumi_N/Status_work\" --load_path \"/depot/cms/users/yun79/results/stage1/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3506c3fc-ce59-4558-a715-ddbf6208a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = ['A', 'B', 'C', 'D']\n",
    "bkg_l = ['DY','TT','ST','VV','EWK']\n",
    "sig_l = ['ggH', 'VBF']\n",
    "vars2plot = ['jet', 'mu', 'dimuon', 'dijet'] \n",
    "lumi = 137.9\n",
    "status = \"Private_Work\"\n",
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd72782-62c0-4ecc-a8d2-fbc219ed7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 1.0\n",
    "fraction_str = str(fraction).replace('.', '_')\n",
    "load_path = f\"/depot/cms/users/yun79/results/stage1/test_full3/{year}/f{fraction_str}\"\n",
    "! python validation_plotter_unified.py -y {year} --load_path {load_path}  -var {' '.join(vars2plot)} --data {' '.join(data_l)} --background {' '.join(bkg_l)} --signal {' '.join(sig_l)} --lumi 137.9 --status {status} --ROOT_style    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e49c2b-55e7-433d-9656-f7aa9984e7c4",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "Now we take the stage1 output for stage2: Categorization of skimmed and selected data into production mode categories. Currently, only ggH production mode is supported.\n",
    "\n",
    "Each category processes the stage1 output through their own MVAs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51588c0a-99d1-40bd-b5db-97512eebde5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_path: /depot/cms/users/yun79/results/stage1/test_VBF-filter_JECon_07June2024/2018/f1_0\n",
      "full_load_path: /depot/cms/users/yun79/results/stage1/test_VBF-filter_JECon_07June2024/2018/f1_0/data_*/*/*.parquet\n",
      "/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40313 instead\n",
      "  warnings.warn(\n",
      "len(training_features): 20\n",
      "sum df.h_peak: 376729.0\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: -0.128, dimuon_eta: 3.67, dimuon_phi_cs: ..., ...}, ...]\n",
      "df_i_feat[:,0]: [-0.128, 0.335, 0.637, -0.771, -0.774, ..., -0.47, -0.969, -0.292, 0.826, 0.738]\n",
      "df_i.dimuon_cos_theta_cs: [-0.128, 0.335, 0.637, -0.771, -0.774, ..., -0.47, -0.969, -0.292, 0.826, 0.738]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.407778   0.4173412  0.3079564  ... 0.3604102  0.7083121  0.39978307]\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: -0.0179, dimuon_eta: 3.16, dimuon_phi_cs: ..., ...}, ...]\n",
      "df_i_feat[:,0]: [-0.0179, -0.885, 0.851, -0.549, 0.804, ..., -0.095, -0.783, -0.9, -0.38]\n",
      "df_i.dimuon_cos_theta_cs: [-0.0179, -0.885, 0.851, -0.549, 0.804, ..., -0.095, -0.783, -0.9, -0.38]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.4887737  0.2828411  0.45126566 ... 0.40130708 0.38903365 0.459111  ]\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: -0.583, dimuon_eta: 2.19, dimuon_phi_cs: ..., ...}, ...]\n",
      "df_i_feat[:,0]: [-0.583, 0.203, -0.26, 0.444, -0.818, ..., 0.743, 0.162, 0.248, 0.55, -0.205]\n",
      "df_i.dimuon_cos_theta_cs: [-0.583, 0.203, -0.26, 0.444, -0.818, ..., 0.743, 0.162, 0.248, 0.55, -0.205]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.20918325 0.28155628 0.30554911 ... 0.24676208 0.3017485  0.47752976]\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: -0.812, dimuon_eta: 2.78, dimuon_phi_cs: ..., ...}, ...]\n",
      "df_i_feat[:,0]: [-0.812, -0.281, -0.666, 0.309, -0.121, ..., -0.04, 0.478, 0.191, 0.925, 0.137]\n",
      "df_i.dimuon_cos_theta_cs: [-0.812, -0.281, -0.666, 0.309, -0.121, ..., -0.04, 0.478, 0.191, 0.925, 0.137]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.8156427  0.40258425 0.42720258 ... 0.2531835  0.32090977 0.57181823]\n",
      "subCat BDT edges: [0.         0.55983555 0.70393234 0.76000953 0.83448213 1.        ]\n",
      "save_path: /work/users/yun79/stage2_output/test/ggh/2018\n",
      "save_filename: /work/users/yun79/stage2_output/test/ggh/2018/processed_events_data.parquet\n",
      "full_load_path: /depot/cms/users/yun79/results/stage1/test_VBF-filter_JECon_07June2024/2018/f1_0/ggh_powheg/*/*.parquet\n",
      "/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42215 instead\n",
      "  warnings.warn(\n",
      "len(training_features): 20\n",
      "sum df.h_peak: 577628.0\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: -0.63, dimuon_eta: -3.5, dimuon_phi_cs: -2.39, ...}, ...]\n",
      "df_i_feat[:,0]: [-0.63, 0.787, 0.422, -0.0983, 0.321, ..., -0.449, 0.118, -0.503, 0.122, -0.884]\n",
      "df_i.dimuon_cos_theta_cs: [-0.63, 0.787, 0.422, -0.0983, 0.321, ..., -0.449, 0.118, -0.503, 0.122, -0.884]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.35937622 0.44262156 0.48845112 ... 0.25177285 0.2954969  0.46936545]\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: -0.0897, dimuon_eta: -2.74, ...}, {...}, ..., {...}]\n",
      "df_i_feat[:,0]: [-0.0897, 0.799, 0.287, -0.385, -0.0949, ..., -0.759, 0.7, 0.344, 0.338, -0.222]\n",
      "df_i.dimuon_cos_theta_cs: [-0.0897, 0.799, 0.287, -0.385, -0.0949, ..., -0.759, 0.7, 0.344, 0.338, -0.222]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.3470872  0.35358256 0.42061836 ... 0.74490994 0.31173575 0.8099201 ]\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: 0.564, dimuon_eta: 1.37, dimuon_phi_cs: 0.944, ...}, ...]\n",
      "df_i_feat[:,0]: [0.564, -0.797, -0.236, -0.668, -0.188, ..., 0.105, 0.361, 0.373, -0.288]\n",
      "df_i.dimuon_cos_theta_cs: [0.564, -0.797, -0.236, -0.668, -0.188, ..., 0.105, 0.361, 0.373, -0.288]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.23771317 0.1706543  0.46378472 ... 0.8946607  0.37170368 0.17565446]\n",
      "scalers: (2, 20)\n",
      "df_i: [{dimuon_cos_theta_cs: 0.124, dimuon_eta: -2.65, dimuon_phi_cs: 3.05, ...}, ...]\n",
      "df_i_feat[:,0]: [0.124, -0.0101, -0.798, 0.752, 0.0361, ..., 0.604, 0.00421, -0.154, -0.724]\n",
      "df_i.dimuon_cos_theta_cs: [0.124, -0.0101, -0.798, 0.752, 0.0361, ..., 0.604, 0.00421, -0.154, -0.724]\n",
      "model: phifixedBDT_2018\n",
      "prediction: [0.2684588  0.2847171  0.37423882 ... 0.47534105 0.40396646 0.63878167]\n",
      "subCat BDT edges: [0.         0.55983555 0.70393234 0.76000953 0.83448213 1.        ]\n",
      "save_path: /work/users/yun79/stage2_output/test/ggh/2018\n",
      "save_filename: /work/users/yun79/stage2_output/test/ggh/2018/processed_events_signalMC.parquet\n",
      "stage2 done in 144.0827841758728 seconds\n",
      "2024-07-29 22:57:39,393 - distributed.scheduler - INFO - Retire worker addresses (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30)\n",
      "2024-07-29 22:57:39,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34703'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,393 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41283'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,394 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33177'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,394 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39321'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,394 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,394 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42203'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,395 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35103'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,395 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43431'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,395 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44553'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,396 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37017'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,396 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42603'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,396 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37279'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36723'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45657'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40891'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,397 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35155'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,398 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,398 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45305'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,398 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,398 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33857'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,398 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,398 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37847'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,399 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,399 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33545'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,399 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,399 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41981'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,399 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,399 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41895'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,400 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,400 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46037'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,400 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,400 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42147'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,400 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,401 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33003'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,401 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41287'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,401 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,401 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43333'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38625'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36139'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,402 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,403 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45145'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,403 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,403 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33463'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,403 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,403 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44147'. Reason: nanny-close\n",
      "2024-07-29 22:57:39,404 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54620; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54580; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54548; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54662; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54638; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54482; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54650; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54706; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54688; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54600; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54570; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54488; closing.\n",
      "2024-07-29 22:57:39,409 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54702; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54562; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54564; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54540; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54718; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54614; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54592; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54492; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54514; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54524; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54732; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54582; closing.\n",
      "2024-07-29 22:57:39,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54726; closing.\n",
      "2024-07-29 22:57:39,411 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41285', name: 0, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4117582')\n",
      "2024-07-29 22:57:39,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43067', name: 2, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4121678')\n",
      "2024-07-29 22:57:39,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44507', name: 3, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4123604')\n",
      "2024-07-29 22:57:39,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46059', name: 4, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4125414')\n",
      "2024-07-29 22:57:39,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33719', name: 5, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4127178')\n",
      "2024-07-29 22:57:39,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41941', name: 8, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4128973')\n",
      "2024-07-29 22:57:39,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42327', name: 7, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4130888')\n",
      "2024-07-29 22:57:39,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40649', name: 9, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.413267')\n",
      "2024-07-29 22:57:39,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45807', name: 10, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4134395')\n",
      "2024-07-29 22:57:39,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46831', name: 11, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4136124')\n",
      "2024-07-29 22:57:39,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34131', name: 12, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4137743')\n",
      "2024-07-29 22:57:39,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46507', name: 13, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4139438')\n",
      "2024-07-29 22:57:39,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41789', name: 14, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4141288')\n",
      "2024-07-29 22:57:39,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37923', name: 15, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4142911')\n",
      "2024-07-29 22:57:39,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43327', name: 16, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.414452')\n",
      "2024-07-29 22:57:39,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43485', name: 18, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4146156')\n",
      "2024-07-29 22:57:39,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33495', name: 19, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4147806')\n",
      "2024-07-29 22:57:39,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40909', name: 6, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4149458')\n",
      "2024-07-29 22:57:39,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40145', name: 1, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4151137')\n",
      "2024-07-29 22:57:39,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40591', name: 21, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4152763')\n",
      "2024-07-29 22:57:39,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35929', name: 22, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4154336')\n",
      "2024-07-29 22:57:39,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45355', name: 23, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4155927')\n",
      "2024-07-29 22:57:39,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45549', name: 24, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.415749')\n",
      "2024-07-29 22:57:39,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45343', name: 25, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4159024')\n",
      "2024-07-29 22:57:39,416 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44205', name: 26, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4160573')\n",
      "2024-07-29 22:57:39,416 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54578; closing.\n",
      "2024-07-29 22:57:39,416 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54470; closing.\n",
      "2024-07-29 22:57:39,416 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54690; closing.\n",
      "2024-07-29 22:57:39,416 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54636; closing.\n",
      "2024-07-29 22:57:39,416 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54506; closing.\n",
      "2024-07-29 22:57:39,416 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:54672; closing.\n",
      "2024-07-29 22:57:39,417 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34849', name: 17, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4174995')\n",
      "2024-07-29 22:57:39,417 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42131', name: 27, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4176745')\n",
      "2024-07-29 22:57:39,417 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44957', name: 28, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4178371')\n",
      "2024-07-29 22:57:39,418 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34377', name: 29, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4179907')\n",
      "2024-07-29 22:57:39,418 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36019', name: 30, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4181495')\n",
      "2024-07-29 22:57:39,418 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46371', name: 20, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1722286659.4183016')\n",
      "2024-07-29 22:57:39,418 - distributed.scheduler - INFO - Lost all workers\n",
      "2024-07-29 22:57:39,418 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:37661 remote=tcp://127.0.0.1:54636>\n",
      "Traceback (most recent call last):\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-07-29 22:57:39,419 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:37661 remote=tcp://127.0.0.1:54578>\n",
      "Traceback (most recent call last):\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-07-29 22:57:39,419 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:37661 remote=tcp://127.0.0.1:54506>\n",
      "Traceback (most recent call last):\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-07-29 22:57:39,420 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:37661 remote=tcp://127.0.0.1:54470>\n",
      "Traceback (most recent call last):\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-07-29 22:57:39,420 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:37661 remote=tcp://127.0.0.1:54690>\n",
      "Traceback (most recent call last):\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-07-29 22:57:39,420 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:37661 remote=tcp://127.0.0.1:54672>\n",
      "Traceback (most recent call last):\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/depot/cms/kernels/root632/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-07-29 22:57:40,293 - distributed.scheduler - INFO - Scheduler closing due to unknown reason...\n",
      "2024-07-29 22:57:40,294 - distributed.scheduler - INFO - Scheduler closing all comms\n"
     ]
    }
   ],
   "source": [
    "stage2_load_path = \"/depot/cms/users/yun79/results/stage1/test_VBF-filter_JECon_07June2024\" # path where stage1 output is saved \n",
    "stage2_save_path = \"/work/users/yun79/stage2_output/test\" # path where stage2 output is saved \n",
    "category = \"ggh\"\n",
    "samples = [\"data\", \"signal\"] # signal here is MC signal sample (ie ggh_powheg)\n",
    "# samples = [\"signal\"] # signal here is MC signal sample (ie ggh_powheg)\n",
    "! python run_stage2.py -load {stage2_load_path} -save {stage2_save_path} --samples {' '.join(samples)} -cat {category}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f401d-dc87-4647-8b83-974d7e87e8ad",
   "metadata": {},
   "source": [
    "# Stage 3\n",
    "Now we do the fitting from the stage2 output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cec76b1-ead3-4899-92d4-8b019525b2f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_path: /work/users/yun79/stage2_output/test/ggh/2018/processed_events_data.parquet\n",
      "events loaded!\n",
      "[#1] INFO:Eval -- RooRealVar::setRange(mh_ggh) new range named 'hiSB' created with bounds [135,150]\n",
      "[#1] INFO:Eval -- RooRealVar::setRange(mh_ggh) new range named 'loSB' created with bounds [110,115]\n",
      "[#1] INFO:Eval -- RooRealVar::setRange(mh_ggh) new range named 'h_peak' created with bounds [115,135]\n",
      "[#1] INFO:Eval -- RooRealVar::setRange(mh_ggh) new range named 'full' created with bounds [110,150]\n",
      "[#0] WARNING:InputArguments -- RooProdPdf::addPdfs(fewz_roospline_func) list arg fewz_roospline_func is not a PDF, ignored\n",
      "[#1] INFO:Eval -- RooRealVar::setRange(mh_ggh) new range named 'fit_nll_simPdf_combData_hiSB' created with bounds [135,150]\n",
      "[#1] INFO:Eval -- RooRealVar::setRange(mh_ggh) new range named 'fit_nll_simPdf_combData_loSB' created with bounds [110,115]\n",
      "[#1] INFO:Fitting -- RooAbsPdf::fitTo(simPdf) fixing normalization set for coefficient determination to observables in data\n",
      "[#1] INFO:Fitting -- using CPU computation library compiled with -mavx2\n",
      "[#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_simPdf_combData) Summation contains a RooNLLVar, using its error level\n",
      "[#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization\n",
      "Minuit2Minimizer: Minimize with max-calls 7500 convergence for edm < 1 strategy 0\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat4_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat4_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat4_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat4_SMF_over_subCat4_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat4_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat4_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat4_SMF_over_subCat4_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat4_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat3_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat3_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat3_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat3_SMF_over_subCat3_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat3_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat3_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat3_SMF_over_subCat3_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat3_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat2_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat2_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat2_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat2_SMF_over_subCat2_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat2_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat2_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat2_SMF_over_subCat2_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat2_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat1_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat1_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat1_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat1_SMF_over_subCat1_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat1_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat1_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat1_SMF_over_subCat1_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat1_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat0_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat0_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat0_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat0_SMF_over_subCat0_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat0_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat0_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat0_SMF_over_subCat0_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat0_BWZRedux_mh_ggh)\n",
      "Minuit2Minimizer : Valid minimum - status = 0\n",
      "FVAL  = 1407286.35169780441\n",
      "Edm   = 7.91291114432993121e-05\n",
      "Nfcn  = 1598\n",
      "BWZ_Redux_a_coeff\t  = 0.00191191\t +/-  0.000325852\t(limited)\n",
      "BWZ_Redux_b_coeff\t  = -0.000129391\t +/-  5.33647e-07\t(limited)\n",
      "BWZ_Redux_c_coeff\t  = 1.21661\t +/-  0.0297155\t(limited)\n",
      "a0_subCat0\t  = 0.383967\t +/-  0.026841\t(limited)\n",
      "a0_subCat1\t  = 0.418528\t +/-  0.028834\t(limited)\n",
      "a0_subCat2\t  = 0.460296\t +/-  0.0368144\t(limited)\n",
      "a0_subCat3\t  = 0.548138\t +/-  0.0283508\t(limited)\n",
      "a0_subCat4\t  = 0.5\t +/-  0.00906191\t(limited)\n",
      "a1_subCat0\t  = 0.105269\t +/-  0.0045822\t(limited)\n",
      "a1_subCat1\t  = 0.112935\t +/-  0.0149029\t(limited)\n",
      "a1_subCat2\t  = 0.0545363\t +/-  0.0318611\t(limited)\n",
      "a1_subCat3\t  = 0.196315\t +/-  0.0265734\t(limited)\n",
      "a1_subCat4\t  = 0.11611\t +/-  0.0295533\t(limited)\n",
      "a3_subCat0\t  = 0.002183\t +/-  0.00340077\t(limited)\n",
      "a3_subCat1\t  = -0.00259256\t +/-  0.0121174\t(limited)\n",
      "Minuit2:0: RuntimeWarning: MnPosDef Matrix forced pos-def by adding to diagonal 0.00541107\n",
      "[#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization\n",
      "[#1] INFO:Fitting -- RooAbsPdf::fitTo(simPdf) fixing normalization set for coefficient determination to observables in data\n",
      "[#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_simPdf_combData) Summation contains a RooNLLVar, using its error level\n",
      "[#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization\n",
      "Minuit2Minimizer: Minimize with max-calls 7500 convergence for edm < 1 strategy 1\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat4_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat4_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat4_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat4_SMF_over_subCat4_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat4_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat4_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat4_SMF_over_subCat4_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat4_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat3_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat3_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat3_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat3_SMF_over_subCat3_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat3_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat3_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat3_SMF_over_subCat3_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat3_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat2_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat2_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat2_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat2_SMF_over_subCat2_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat2_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat2_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat2_SMF_over_subCat2_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat2_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat1_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat1_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat1_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat1_SMF_over_subCat1_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat1_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat1_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat1_SMF_over_subCat1_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat1_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat0_BWZRedux_subCat0_BWZ_Redux_Int[mh_ggh]) using numeric integrator RooIntegrator1D to calculate Int(_subCat0_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat0_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat0_SMF_over_subCat0_SMF_Int[mh_ggh]]_Int[mh_ggh|loSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat0_BWZRedux_mh_ggh)\n",
      "[#1] INFO:NumericIntegration -- RooRealIntegral::init(_subCat0_BWZRedux_[subCat0_BWZ_Redux_over_subCat0_BWZ_Redux_Int[mh_ggh]_X_subCat0_SMF_over_subCat0_SMF_Int[mh_ggh]]_Int[mh_ggh|hiSB]) using numeric integrator RooIntegrator1D to calculate Int(_subCat0_BWZRedux_mh_ggh)\n",
      "Minuit2:0: RuntimeWarning: MnPosDef Matrix forced pos-def by adding to diagonal 0.00541196\n",
      "Minuit2:0: RuntimeWarning: VariableMetricBuilder Reached machine accuracy limit; Edm 0.00605052 is smaller than machine limit 0.0838808 while 0.001 was requested\n",
      "Minuit2:0: RuntimeWarning: Minuit2Minimizer::Minimize Covar was made pos def\n",
      "Minuit2Minimizer : Valid minimum - status = 1\n",
      "FVAL  = 1407286.35164903686\n",
      "Edm   = 0.00605051942049670416\n",
      "Nfcn  = 278\n",
      "BWZ_Redux_a_coeff\t  = 0.00191237\t +/-  0.00145868\t(limited)\n",
      "BWZ_Redux_b_coeff\t  = -0.000129388\t +/-  5.70016e-06\t(limited)\n",
      "BWZ_Redux_c_coeff\t  = 1.21663\t +/-  0.0373276\t(limited)\n",
      "a0_subCat0\t  = 0.383963\t +/-  0.0249975\t(limited)\n",
      "a0_subCat1\t  = 0.418512\t +/-  0.0277625\t(limited)\n",
      "a0_subCat2\t  = 0.460208\t +/-  0.0353879\t(limited)\n",
      "a0_subCat3\t  = 0.548057\t +/-  0.0334816\t(limited)\n",
      "a0_subCat4\t  = 0.5\t +/-  0.0490156\t(limited)\n",
      "a1_subCat0\t  = 0.105258\t +/-  0.00695403\t(limited)\n",
      "a1_subCat1\t  = 0.112938\t +/-  0.0179127\t(limited)\n",
      "a1_subCat2\t  = 0.0545553\t +/-  0.0348\t(limited)\n",
      "a1_subCat3\t  = 0.196272\t +/-  0.0322958\t(limited)\n",
      "a1_subCat4\t  = 0.116218\t +/-  0.0311622\t(limited)\n",
      "a3_subCat0\t  = 0.00218872\t +/-  0.00346804\t(limited)\n",
      "a3_subCat1\t  = -0.00260347\t +/-  0.0117444\t(limited)\n",
      "Minuit2:0: RuntimeWarning: MnPosDef Matrix forced pos-def by adding to diagonal 0.00477902\n",
      "[#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization\n",
      "\n",
      "  RooFitResult: minimized FCN value: 1.40729e+06, estimated distance to minimum: 0.00694518\n",
      "                covariance matrix quality: Full matrix, but forced positive-definite\n",
      "                Status : MINIMIZE=1 HESSE=1 \n",
      "\n",
      "    Floating Parameter    FinalValue +/-  Error   \n",
      "  --------------------  --------------------------\n",
      "     BWZ_Redux_a_coeff    1.9124e-03 +/-  1.49e-03\n",
      "     BWZ_Redux_b_coeff   -1.2939e-04 +/-  5.74e-06\n",
      "     BWZ_Redux_c_coeff    1.2166e+00 +/-  4.17e-02\n",
      "            a0_subCat0    3.8396e-01 +/-  2.54e-02\n",
      "            a0_subCat1    4.1851e-01 +/-  2.81e-02\n",
      "            a0_subCat2    4.6021e-01 +/-  3.56e-02\n",
      "            a0_subCat3    5.4806e-01 +/-  3.38e-02\n",
      "            a0_subCat4    5.0000e-01 +/-  1.56e-02\n",
      "            a1_subCat0    1.0526e-01 +/-  7.07e-03\n",
      "            a1_subCat1    1.1294e-01 +/-  1.81e-02\n",
      "            a1_subCat2    5.4555e-02 +/-  3.51e-02\n",
      "            a1_subCat3    1.9627e-01 +/-  3.27e-02\n",
      "            a1_subCat4    1.1622e-01 +/-  3.17e-02\n",
      "            a3_subCat0    2.1887e-03 +/-  3.51e-03\n",
      "            a3_subCat1   -2.6035e-03 +/-  1.18e-02\n",
      "\n",
      "runtime: 1.4577081203460693 seconds\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/users/yun79/valerie/fork/copperheadV2/run_stage3.py\", line 614, in <module>\n",
      "    raise ValueError\n",
      "ValueError\n"
     ]
    }
   ],
   "source": [
    "stage3_load_path = stage2_save_path\n",
    "! python run_stage3.py -load {stage3_load_path} -cat {category}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450a774-b3ce-4aec-910d-580d275e68d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root632]",
   "language": "python",
   "name": "conda-env-root632-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
